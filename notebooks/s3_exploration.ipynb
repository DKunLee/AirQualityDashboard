{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb as ddb\n",
    "\n",
    "# Installing and loading the HTTPFS extension to handle file access via HTTP/S\n",
    "ddb.sql(\"INSTALL httpfs; LOAD httpfs\")\n",
    "\n",
    "con = ddb.connect(\"../air_quality.db\")\n",
    "\n",
    "# Creating a schema named 'raw' if it does not already exist\n",
    "con.execute(\"CREATE schema IF NOT EXISTS raw\")\n",
    "\n",
    "# Setting up credentials for accessing S3 (empty here, presumably placeholders for real credentials)\n",
    "con.sql(\"\"\"\n",
    "    SET s3_access_key_id='';\n",
    "    SET s3_secret_access_key='';\n",
    "    SET s3_region='';\n",
    "\"\"\")\n",
    "\n",
    "# Creating a table 'air_quality_data' within the 'raw' schema if it does not already exist\n",
    "# The table is designed to store air quality data with columns for location, time, coordinates, parameters, and more\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS raw.air_quality_data (\n",
    "        location_id BIGINT,\n",
    "        sensors_id BIGINT,\n",
    "        \"location\" VARCHAR,\n",
    "        \"datetime\" TIMESTAMP,\n",
    "        lat DOUBLE,\n",
    "        lon DOUBLE,\n",
    "        \"parameter\" VARCHAR,\n",
    "        units VARCHAR,\n",
    "        \"value\" DOUBLE,\n",
    "        \"month\" VARCHAR,\n",
    "        \"year\" BIGINT,\n",
    "        ingestion_datetime TIMESTAMP\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Inserting data into the 'raw.air_quality_data' table from a CSV file stored in an S3 bucket\n",
    "# Data is read from a compressed file using the 'read_csv' function\n",
    "con.execute(\"\"\"\n",
    "    INSERT INTO raw.air_quality_data\n",
    "    SELECT \n",
    "        location_id, \n",
    "        sensors_id, \n",
    "        \"location\", \n",
    "        \"datetime\", \n",
    "        lat, \n",
    "        lon, \n",
    "        \"parameter\", \n",
    "        units, \n",
    "        \"value\",\n",
    "        \"month\", \n",
    "        \"year\",\n",
    "        current_timestamp AS ingestion_datetime\n",
    "    FROM read_csv('s3://openaq-data-archive/records/csv.gz/locationid=2027500/year=2024/month=01/*.csv.gz');\n",
    "\"\"\")\n",
    "\n",
    "con.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
